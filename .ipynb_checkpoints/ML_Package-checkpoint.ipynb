{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ckAZ6h6ycm1"
   },
   "source": [
    "Need to mount the drive to acess the dataset since the dataset is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-_vFUC-Ij4K",
    "outputId": "199326c8-73d5-4e9d-bb5b-65ecef973a61"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSAK7QoJqedU",
    "outputId": "71837001-f87c-448d-d511-c85b1dee26da"
   },
   "outputs": [],
   "source": [
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtW_NqCUQEcH",
    "outputId": "9fdd6727-0ec6-42b4-cf74-f5be7cec899d"
   },
   "outputs": [],
   "source": [
    "!pip install lime shap scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-y41PzvyJK-"
   },
   "source": [
    "###Imports and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMfcmrpsyBxR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "import seaborn as sns\n",
    "import librosa.display\n",
    "import librosa\n",
    "from tempfile import TemporaryFile\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import operator\n",
    "\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Additional libraries for data preprocessing and visualization\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NjGXkhLWGKo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "Root = \"/content/drive/MyDrive/Data\"\n",
    "os.chdir(Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "FGosQEcVWlZX",
    "outputId": "ff686dc4-c7ee-49d8-ef37-bec3d534f5a4"
   },
   "outputs": [],
   "source": [
    "audio_data_path = \"/content/drive/MyDrive/Data/genres_original\"\n",
    "music_data = pd.read_csv(\"./features_3_sec.csv\")\n",
    "music_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-AdW3mgRjrdT",
    "outputId": "5fe419ee-a549-4137-b526-0c322634aa9e"
   },
   "outputs": [],
   "source": [
    "music_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2iKgLwH0Hwg"
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bm40Od27mI1"
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import librosa\n",
    "from importlib import reload\n",
    "plt=reload(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "R37nkjNc8K8E",
    "outputId": "28fecdcd-fdb7-4817-ff43-3b00e4119b8c"
   },
   "outputs": [],
   "source": [
    "base_path = '/content/drive/MyDrive/Data/genres_original/'\n",
    "\n",
    "# List of genre folders\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "# Create a figure for plotting\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Loop through each genre and plot the waveform\n",
    "for i, genre in enumerate(genres):\n",
    "    # Get the list of audio files in the genre folder\n",
    "    genre_folder = os.path.join(base_path, genre)\n",
    "    audio_files = os.listdir(genre_folder)\n",
    "\n",
    "    # Plot the first audio file in the genre\n",
    "    path = os.path.join(genre_folder, audio_files[0])\n",
    "\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    x, sr = librosa.load(path)\n",
    "    librosa.display.waveshow(x, sr=sr)\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'Waveform of the Genre {genre}')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPK7T6koDgHp"
   },
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "qYKfvO4iDf0R",
    "outputId": "6c21158c-917f-457a-919d-4cff74f0b64d"
   },
   "outputs": [],
   "source": [
    "# Computing the Correlation Matrix\n",
    "spike_cols = [col for col in music_data.columns if 'mean' in col]\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(16, 11));\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(music_data[spike_cols].corr(), cmap='YlGn')\n",
    "\n",
    "plt.title('Heatmap for MEAN variables', fontsize = 20)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnSL_yW7ENJ2"
   },
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zZg4bpeaEOLS",
    "outputId": "6fb4d959-91db-4db8-f3c4-b69ce9f801f7"
   },
   "outputs": [],
   "source": [
    "data, sr = librosa.load('/content/drive/MyDrive/Data/genres_original/blues/blues.00000.wav')\n",
    "stft = librosa.stft(data)\n",
    "stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "plt.figure(figsize =(14, 6))\n",
    "librosa.display.specshow(stft, sr=sr, x_axis = 'time', y_axis = 'hz')\n",
    "plt.ylim(0, 200)\n",
    "plt.title('Spectogram for Genre Blue')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "GsJx1uYaE1cg",
    "outputId": "2d153463-7ec1-4127-b0c8-5f5be3dad2b4"
   },
   "outputs": [],
   "source": [
    "spectral_rolloff = librosa.feature.spectral_rolloff(y = data, sr=sr)[0]\n",
    "plt.figure(figsize = (12, 4))\n",
    "librosa.display.waveshow(data, sr=sr, alpha = 0.4, color = \"#2B4F72\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XJAjarhlE1T5",
    "outputId": "c26c77c2-bc0c-4fb8-8a68-51804046b9fd"
   },
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_stft(y = data, sr = sr)\n",
    "plt.figure(figsize = (16,6))\n",
    "librosa.display.specshow(chroma, sr = sr, x_axis='time', y_axis='chroma', cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title('Chroma Feature for Genre Blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ByQ8FxkvE4xK",
    "outputId": "3b8a7338-be12-428e-a3a3-b2f2c1634edc"
   },
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)\n",
    "\n",
    "# Display the MFCCs\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mfccs, x_axis='time', sr=sr)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UF-6Ui9E8mN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5ZKGE0IjsZQ"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zaCnmmsyOGf"
   },
   "source": [
    "*Define a function to get the distance between feature vectors and find neighbors:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bo4h27WyOk5"
   },
   "outputs": [],
   "source": [
    "def getNeighbors(trainingSet, instance, k):\n",
    "    distances = []\n",
    "    for x in range (len(trainingSet)):\n",
    "        dist = distance(trainingSet[x], instance, k )+ distance(instance, trainingSet[x], k)\n",
    "        distances.append((trainingSet[x][2], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeS4FdqwyR33"
   },
   "source": [
    "Identify the nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsFLxmBdyUnB"
   },
   "outputs": [],
   "source": [
    "def nearestClass(neighbors):\n",
    "    classVote = {}\n",
    "\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVote:\n",
    "            classVote[response]+=1\n",
    "        else:\n",
    "            classVote[response]=1\n",
    "\n",
    "    sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    return sorter[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDSbtUZayXKC"
   },
   "source": [
    "Define a function for model evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0j3JdfE8zFR3"
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range (len(testSet)):\n",
    "        if testSet[x][-1]==predictions[x]:\n",
    "            correct+=1\n",
    "    return 1.0*correct/len(testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQjnpeCczJgn"
   },
   "source": [
    "Extract features from the dataset and dump these features into a binary .dat file “my.dat”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nUS3EyWzJ6p",
    "outputId": "ef226d52-293a-4ca8-a591-a2bbe8c546c6"
   },
   "outputs": [],
   "source": [
    "directory = audio_data_path\n",
    "f = open(\"mydataset.dat\", \"wb\")\n",
    "i = 0\n",
    "for folder in os.listdir(directory):\n",
    "    #print(folder)\n",
    "    i += 1\n",
    "    if i == 11:\n",
    "        break\n",
    "    for file in os.listdir(directory+\"/\"+folder):\n",
    "        #print(file)\n",
    "        try:\n",
    "            (rate, sig) = wav.read(directory+\"/\"+folder+\"/\"+file)\n",
    "            mfcc_feat = mfcc(sig, rate, winlen = 0.020, appendEnergy=False)\n",
    "            covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "            mean_matrix = mfcc_feat.mean(0)\n",
    "            feature = (mean_matrix, covariance, i)\n",
    "            pickle.dump(feature, f)\n",
    "        except Exception as e:\n",
    "            print(\"Got an exception: \", e, 'in folder: ', folder, ' filename: ', file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWriBSLdzNNS"
   },
   "source": [
    "Train and test split on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FEMPQjTzQP0"
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "def loadDataset(filename, split, trset, teset):\n",
    "    with open('mydataset.dat','rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break\n",
    "    for x in range(len(dataset)):\n",
    "        if random.random() < split:\n",
    "            trset.append(dataset[x])\n",
    "        else:\n",
    "            teset.append(dataset[x])\n",
    "\n",
    "trainingSet = []\n",
    "testSet = []\n",
    "loadDataset(music_data, 0.68, trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzWTOOagF6X-"
   },
   "outputs": [],
   "source": [
    "def distance(instance1, instance2, k):\n",
    "    distance = 0\n",
    "    mm1 = instance1[0]\n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1))\n",
    "    distance += (np.dot(np.dot((mm2-mm1).transpose(), np.linalg.inv(cm2)), mm2-mm1))\n",
    "    distance += np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    distance -= k\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcVvC9m4zTK0"
   },
   "source": [
    "Make prediction using KNN and get the accuracy on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OCJ7WcfzVji",
    "outputId": "92d70d7a-bf8c-4883-c410-c36b10309e28"
   },
   "outputs": [],
   "source": [
    "# Make the prediction using KNN(K nearest Neighbors)\n",
    "length = len(testSet)\n",
    "predictions = []\n",
    "for x in range(length):\n",
    "    predictions.append(nearestClass(getNeighbors(trainingSet, testSet[x], 5)))\n",
    "\n",
    "accuracy1 = getAccuracy(testSet, predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOW1aqQBzYET"
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMMQcEtFRGEU",
    "outputId": "72e98f87-fbd5-4ed9-d088-a28aa733e85b"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(int)\n",
    "\n",
    "directory = audio_data_path\n",
    "i = 1\n",
    "for folder in os.listdir(directory):\n",
    "    results[i] = folder\n",
    "    i += 1\n",
    "\n",
    "\n",
    "pred = nearestClass(getNeighbors(dataset, feature, 5))\n",
    "print(results[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2PDcDoWN64I"
   },
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "lYvmfsyGOAHp",
    "outputId": "685c43b5-a4b6-44a8-8201-64306d01a21a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = pd.read_csv('/content/drive/MyDrive/Data/features_3_sec.csv')\n",
    "data = data.iloc[0:, 1:]\n",
    "y = data['label']\n",
    "X = data.loc[:, data.columns != 'label']\n",
    "cols = X.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "scaled_df = pd.DataFrame(np_scaled, columns = cols)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTUO7LZS1Gmr",
    "outputId": "3b485224-6d59-45c1-f662-67edaf4f6905"
   },
   "outputs": [],
   "source": [
    "# Assuming X contains your features and y contains the corresponding labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54eatV6o16M9",
    "outputId": "5ef5b631-53f4-4d4f-aebb-5b6b24d249e1"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Print best model parameters\n",
    "print(\"Best Random Forest Model Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Print feature importances if available\n",
    "if hasattr(best_rf_model, 'feature_importances_'):\n",
    "    feature_importances = dict(zip(X_train.columns, best_rf_model.feature_importances_))\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(pd.Series(feature_importances).sort_values(ascending=False))\n",
    "\n",
    "# Print accuracy on the training set\n",
    "train_predictions = best_rf_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(\"\\nTraining Accuracy:\", train_accuracy)\n",
    "\n",
    "# Print accuracy on the test set\n",
    "test_predictions = best_rf_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPgg48QkQARQ"
   },
   "source": [
    "Lime and Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2enWHcHBP_kv",
    "outputId": "337b30b7-03f3-4a53-de2d-01c28f6a69cb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "\n",
    "data = pd.read_csv('/content/drive/MyDrive/Data/features_3_sec.csv')\n",
    "data = data.iloc[0:, 1:]\n",
    "y = data['label']\n",
    "X = data.loc[:, data.columns != 'label']\n",
    "cols = X.columns\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "print(f'KNN Accuracy: {accuracy_score(y_test, knn_predictions):.2f}')\n",
    "print(f'Random Forest Accuracy: {accuracy_score(y_test, rf_predictions):.2f}')\n",
    "\n",
    "# LIME for KNN\n",
    "knn_explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=y.unique())\n",
    "knn_exp = knn_explainer.explain_instance(X_test.iloc[0].values, knn_model.predict_proba)\n",
    "\n",
    "# LIME for Random Forest\n",
    "rf_explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=y.unique())\n",
    "rf_exp = rf_explainer.explain_instance(X_test.iloc[0].values, rf_model.predict_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD0pWmFvbTK_"
   },
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHieQ5hNbWML"
   },
   "outputs": [],
   "source": [
    "!pip install -q streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wrtV_QqdGhH"
   },
   "source": [
    "### App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFG0s8w9bdIt",
    "outputId": "475e8193-2387-4b4b-8868-07a04ba1329d"
   },
   "outputs": [],
   "source": [
    "%%writefile App.py\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "import seaborn as sns\n",
    "import librosa.display\n",
    "import librosa\n",
    "from collections import defaultdict\n",
    "from tempfile import TemporaryFile\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial import distance\n",
    "from lime import lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import operator\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Additional libraries for data preprocessing and visualization\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "st.set_page_config(page_title='MusicMapping', layout=\"wide\")\n",
    "st.title('Music Genere Classification')\n",
    "\n",
    "st.sidebar.image('https://editor.analyticsvidhya.com/uploads/94476Music%20Genre%20Classification%20Project.png')\n",
    "st.sidebar.write('Developed by ')\n",
    "st.sidebar.write('V K Deeksha - 21PD37')\n",
    "st.sidebar.write('M Aiswarya - 21PD20')\n",
    "\n",
    "\n",
    "# Create tabs\n",
    "tab1, tab2, tab3, tab4, tab5 = st.tabs([\"Overview and Data\",\"📈 Visualize\",\"KNN-Model\",\"RandomForest_Model\",\"Prediction\"])\n",
    "\n",
    "Root = \"/content/drive/MyDrive/Data\"\n",
    "os.chdir(Root)\n",
    "audio_data_path = \"/content/drive/MyDrive/Data/genres_original\"\n",
    "\n",
    "with tab1:\n",
    "    st.header(\"Overview\")\n",
    "    st.markdown(\"Certainly! A music genre classification project involves building a system that can automatically categorize music tracks into predefined genres based on their audio features. This type of project is often approached using machine learning techniques, where the model learns patterns and characteristics of different genres from a labeled dataset.\")\n",
    "    st.markdown('---')\n",
    "    st.markdown('GTZAN MUSIC dataset is a vast collection of audio music files.')\n",
    "    music_data = pd.read_csv(\"/content/drive/MyDrive/Data/features_30_sec.csv\")\n",
    "    st.write(\"GTZAN Dataset:\")\n",
    "    st.write(music_data)\n",
    "\n",
    "\n",
    "with tab2:\n",
    "    st.header(\"Visualization\")\n",
    "\n",
    "    st.subheader(\"Waveform of every Genere\")\n",
    "    from importlib import reload\n",
    "    plt=reload(plt)\n",
    "    base_path = '/content/drive/MyDrive/Data/genres_original/'\n",
    "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    for i, genre in enumerate(genres):\n",
    "        # Get the list of audio files in the genre folder\n",
    "        genre_folder = os.path.join(base_path, genre)\n",
    "        audio_files = os.listdir(genre_folder)\n",
    "\n",
    "        # Plot the first audio file in the genre\n",
    "        path = os.path.join(genre_folder, audio_files[0])\n",
    "\n",
    "        plt.subplot(5, 2, i + 1)\n",
    "        x, sr = librosa.load(path)\n",
    "        librosa.display.waveshow(x, sr=sr)\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title(f'Waveform of the Genre {genre}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    st.pyplot(plt)\n",
    "\n",
    "    st.subheader(\"Heatmap\")\n",
    "    spike_cols = [col for col in music_data.columns if 'mean' in col]\n",
    "    fig, ax = plt.subplots(figsize=(16, 11))\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(music_data[spike_cols].corr(), cmap='YlGn', ax=ax)\n",
    "    plt.title('Heatmap for MEAN variables', fontsize=20)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    st.subheader(\"Genre Spectrogram Viewer\")\n",
    "    genres_path = '/content/drive/MyDrive/Data/genres_original/'\n",
    "    genres = os.listdir(genres_path)\n",
    "    selected_genre = st.selectbox('Select Genre', genres)\n",
    "    audio_path = os.path.join(genres_path, selected_genre, f'{selected_genre}.00000.wav')\n",
    "    data, sr = librosa.load(audio_path)\n",
    "    stft = librosa.stft(data)\n",
    "    stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "    # Display the spectrogram using Matplotlib\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    librosa.display.specshow(stft_db, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.ylim(0, 200)\n",
    "    plt.title(f'Spectrogram for Genre {selected_genre.capitalize()}')\n",
    "    plt.colorbar()\n",
    "    st.pyplot(plt)\n",
    "\n",
    "    st.subheader(\"MFCC Visualization\")\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)\n",
    "    # Display the MFCCs using Matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    img = librosa.display.specshow(mfccs, x_axis='time', sr=sr, ax=ax)\n",
    "    fig.colorbar(img, format='%+2.0f dB')\n",
    "    # Display the plot using Streamlit\n",
    "    st.pyplot(fig)\n",
    "\n",
    "with tab3:\n",
    "    st.header(\"KNN Model and Lime Explanations\")\n",
    "    def getNeighbors(trainingSet, instance, k):\n",
    "        distances = []\n",
    "        for x in range (len(trainingSet)):\n",
    "            dist = distance(trainingSet[x], instance, k )+ distance(instance, trainingSet[x], k)\n",
    "            distances.append((trainingSet[x][2], dist))\n",
    "        distances.sort(key=operator.itemgetter(1))\n",
    "        neighbors = []\n",
    "        for x in range(k):\n",
    "            neighbors.append(distances[x][0])\n",
    "        return neighbors\n",
    "\n",
    "    def nearestClass(neighbors):\n",
    "        classVote = {}\n",
    "\n",
    "        for x in range(len(neighbors)):\n",
    "            response = neighbors[x]\n",
    "            if response in classVote:\n",
    "                classVote[response]+=1\n",
    "            else:\n",
    "                classVote[response]=1\n",
    "\n",
    "        sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "        return sorter[0][0]\n",
    "\n",
    "    def getAccuracy(testSet, predictions):\n",
    "        correct = 0\n",
    "        for x in range (len(testSet)):\n",
    "            if testSet[x][-1]==predictions[x]:\n",
    "                correct+=1\n",
    "        return 1.0*correct/len(testSet)\n",
    "\n",
    "    directory = audio_data_path\n",
    "    f = open(\"mydataset.dat\", \"wb\")\n",
    "    i = 0\n",
    "    for folder in os.listdir(directory):\n",
    "        #print(folder)\n",
    "        i += 1\n",
    "        if i == 11:\n",
    "            break\n",
    "        for file in os.listdir(directory+\"/\"+folder):\n",
    "            #print(file)\n",
    "            try:\n",
    "                (rate, sig) = wav.read(directory+\"/\"+folder+\"/\"+file)\n",
    "                mfcc_feat = mfcc(sig, rate, winlen = 0.020, appendEnergy=False)\n",
    "                covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "                mean_matrix = mfcc_feat.mean(0)\n",
    "                feature = (mean_matrix, covariance, i)\n",
    "                pickle.dump(feature, f)\n",
    "            except Exception as e:\n",
    "                print(\"Got an exception: \", e, 'in folder: ', folder, ' filename: ', file)\n",
    "    f.close()\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    def loadDataset(filename, split, trset, teset):\n",
    "        with open('mydataset.dat','rb') as f:\n",
    "            while True:\n",
    "                try:\n",
    "                    dataset.append(pickle.load(f))\n",
    "                except EOFError:\n",
    "                    f.close()\n",
    "                    break\n",
    "        for x in range(len(dataset)):\n",
    "            if random.random() < split:\n",
    "                trset.append(dataset[x])\n",
    "            else:\n",
    "                teset.append(dataset[x])\n",
    "\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    loadDataset(music_data, 0.68, trainingSet, testSet)\n",
    "\n",
    "    def distance(instance1, instance2, k):\n",
    "        distance = 0\n",
    "        mm1 = instance1[0]\n",
    "        cm1 = instance1[1]\n",
    "        mm2 = instance2[0]\n",
    "        cm2 = instance2[1]\n",
    "        distance = np.trace(np.dot(np.linalg.inv(cm2), cm1))\n",
    "        distance += (np.dot(np.dot((mm2-mm1).transpose(), np.linalg.inv(cm2)), mm2-mm1))\n",
    "        distance += np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "        distance -= k\n",
    "        return distance\n",
    "\n",
    "    # Make the prediction using KNN(K nearest Neighbors)\n",
    "    length = len(testSet)\n",
    "    predictions = []\n",
    "    for x in range(length):\n",
    "        predictions.append(nearestClass(getNeighbors(trainingSet, testSet[x], 5)))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    st.write(f\"Accuracy of the KNN Model: {accuracy:.2%}\")\n",
    "\n",
    "    # Lime Explanations\n",
    "    st.subheader(\"Lime Explanations\")\n",
    "    data = pd.read_csv('/content/drive/MyDrive/Data/features_30_sec.csv')\n",
    "    data = data.iloc[0:, 1:]\n",
    "    y = data['label']\n",
    "    X = data.loc[:, data.columns != 'label']\n",
    "    cols = X.columns\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train KNN model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    st.write(\"Lime Explanation:\")\n",
    "    knn_explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=y.unique())\n",
    "    knn_exp = knn_explainer.explain_instance(X_test.iloc[0].values, knn_model.predict_proba)\n",
    "    st.write(knn_exp)\n",
    "\n",
    "with tab4:\n",
    "    st.header(\"RandomForest Model\")\n",
    "    data = pd.read_csv('/content/drive/MyDrive/Data/features_30_sec.csv')\n",
    "    data = data.iloc[0:, 1:]\n",
    "    y = data['label']\n",
    "    X = data.loc[:, data.columns != 'label']\n",
    "    cols = X.columns\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    np_scaled = min_max_scaler.fit_transform(X)\n",
    "    scaled_df = pd.DataFrame(np_scaled, columns = cols)\n",
    "    st.write(\"Scaled Data:\")\n",
    "    st.write(scaled_df.head())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_df, y, test_size=0.2, random_state=42)\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    st.write(\"Classification Report:\")\n",
    "    st.write(class_report)\n",
    "    st.subheader(\"After hyperparameter Tuning:\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "    }\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    best_rf_model.fit(X_train, y_train)\n",
    "    st.write(\"Best Random Forest Model Parameters:\")\n",
    "    st.write(best_params)\n",
    "    if hasattr(best_rf_model, 'feature_importances_'):\n",
    "        feature_importances = dict(zip(X_train.columns, best_rf_model.feature_importances_))\n",
    "        st.write(\"Feature Importances:\")\n",
    "        st.write(pd.Series(feature_importances).sort_values(ascending=False))\n",
    "    train_predictions = best_rf_model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    st.write(f\"Training Accuracy After predicting using the best model:{train_accuracy}\")\n",
    "    test_predictions = best_rf_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    st.write(f\"Test Accuracy After predicting using the best model:{test_accuracy}\")\n",
    "    # Create a LIME explainer\n",
    "    # LIME for Random Forest\n",
    "    rf_explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=y.unique())\n",
    "    rf_exp = rf_explainer.explain_instance(X_test.iloc[0].values, best_rf_model.predict_proba)\n",
    "    st.write(\"Lime Explanation:\")\n",
    "    st.write(rf_exp)\n",
    "\n",
    "with tab5:\n",
    "    st.header('Audio Genre Prediction')\n",
    "    def getNeighbors(trainingSet, instance, k):\n",
    "        distances = []\n",
    "        for x in range (len(trainingSet)):\n",
    "            dist = distance(trainingSet[x], instance, k )+ distance(instance, trainingSet[x], k)\n",
    "            distances.append((trainingSet[x][2], dist))\n",
    "        distances.sort(key=operator.itemgetter(1))\n",
    "        neighbors = []\n",
    "        for x in range(k):\n",
    "            neighbors.append(distances[x][0])\n",
    "        return neighbors\n",
    "\n",
    "    def nearestClass(neighbors):\n",
    "        classVote = {}\n",
    "\n",
    "        for x in range(len(neighbors)):\n",
    "            response = neighbors[x]\n",
    "            if response in classVote:\n",
    "                classVote[response]+=1\n",
    "            else:\n",
    "                classVote[response]=1\n",
    "\n",
    "        sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "        return sorter[0][0]\n",
    "\n",
    "    def getAccuracy(testSet, predictions):\n",
    "        correct = 0\n",
    "        for x in range (len(testSet)):\n",
    "            if testSet[x][-1]==predictions[x]:\n",
    "                correct+=1\n",
    "        return 1.0*correct/len(testSet)\n",
    "\n",
    "    directory = audio_data_path\n",
    "    f = open(\"mydataset.dat\", \"wb\")\n",
    "    i = 0\n",
    "    for folder in os.listdir(directory):\n",
    "        #print(folder)\n",
    "        i += 1\n",
    "        if i == 11:\n",
    "            break\n",
    "        for file in os.listdir(directory+\"/\"+folder):\n",
    "            #print(file)\n",
    "            try:\n",
    "                (rate, sig) = wav.read(directory+\"/\"+folder+\"/\"+file)\n",
    "                mfcc_feat = mfcc(sig, rate, winlen = 0.020, appendEnergy=False)\n",
    "                covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "                mean_matrix = mfcc_feat.mean(0)\n",
    "                feature = (mean_matrix, covariance, i)\n",
    "                pickle.dump(feature, f)\n",
    "            except Exception as e:\n",
    "                print(\"Got an exception: \", e, 'in folder: ', folder, ' filename: ', file)\n",
    "    f.close()\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    def loadDataset(filename, split, trset, teset):\n",
    "        with open('mydataset.dat','rb') as f:\n",
    "            while True:\n",
    "                try:\n",
    "                    dataset.append(pickle.load(f))\n",
    "                except EOFError:\n",
    "                    f.close()\n",
    "                    break\n",
    "        for x in range(len(dataset)):\n",
    "            if random.random() < split:\n",
    "                trset.append(dataset[x])\n",
    "            else:\n",
    "                teset.append(dataset[x])\n",
    "\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    loadDataset(music_data, 0.68, trainingSet, testSet)\n",
    "\n",
    "    def distance(instance1, instance2, k):\n",
    "        distance = 0\n",
    "        mm1 = instance1[0]\n",
    "        cm1 = instance1[1]\n",
    "        mm2 = instance2[0]\n",
    "        cm2 = instance2[1]\n",
    "        distance = np.trace(np.dot(np.linalg.inv(cm2), cm1))\n",
    "        distance += (np.dot(np.dot((mm2-mm1).transpose(), np.linalg.inv(cm2)), mm2-mm1))\n",
    "        distance += np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "        distance -= k\n",
    "        return distance\n",
    "\n",
    "    # Make the prediction using KNN(K nearest Neighbors)\n",
    "    length = len(testSet)\n",
    "    predictions = []\n",
    "    for x in range(length):\n",
    "        predictions.append(nearestClass(getNeighbors(trainingSet, testSet[x], 5)))\n",
    "\n",
    "    def predict_genre(audio_file):\n",
    "      results = defaultdict(int)\n",
    "      directory = audio_data_path\n",
    "      i = 1\n",
    "      for folder in os.listdir(directory):\n",
    "          results[i] = folder\n",
    "          i += 1\n",
    "      pred = nearestClass(getNeighbors(dataset, feature, 5))\n",
    "      return (results[pred])\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Upload an audio file\", type=['mp3', 'wav'])\n",
    "    if uploaded_file:\n",
    "        st.audio(uploaded_file)\n",
    "        prediction = predict_genre(uploaded_file)\n",
    "        st.write(f\"Predicted Genre: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMA7bB0CbuYX"
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGjOcJ31bi_7",
    "outputId": "6f193f1f-ee2e-49bc-b914-e003d54dae96"
   },
   "outputs": [],
   "source": [
    "!npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLNKo8evbu5z",
    "outputId": "5e576d0f-5f19-4040-ea7b-b462ef943794"
   },
   "outputs": [],
   "source": [
    "!streamlit run App.py &>/content/logs.txt & curl ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e29M2fEVbxN_",
    "outputId": "f16783b3-1b65-4d7d-a08f-95248375897c"
   },
   "outputs": [],
   "source": [
    "!npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "X-y41PzvyJK-",
    "f2iKgLwH0Hwg",
    "zPK7T6koDgHp",
    "xnSL_yW7ENJ2",
    "w5ZKGE0IjsZQ",
    "M2PDcDoWN64I",
    "0wrtV_QqdGhH"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
